{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные\n",
    " * При первом запуске скачаем train.csv и evaluation.csv\n",
    " * При повторных запусках файлы уже будут на месте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_url = \"https://www.dropbox.com/s/482zjl1hzgvej92/test.csv?dl=1\"\n",
    "training_url = \"https://www.dropbox.com/s/4y54q61b6s18ofh/train.csv?dl=1\"\n",
    "evaluation_path = \"test.csv\"\n",
    "training_path = \"train.csv\"\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "if not os.path.exists(evaluation_path):\n",
    "    urlretrieve(evaluation_url,evaluation_path)\n",
    "if not os.path.exists(training_path):\n",
    "    urlretrieve(training_url,training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Если у вас слабый компьютер - можно взять подвыборку данных\n",
    "#data = data[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_col = [ 'dist','due', 'lat','lon','f_class','s_class','t_class',]\n",
    "X_raw = data[x_col]\n",
    "y = data['burned'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Простое решение\n",
    "- Сделаем One-Hot encoding для всех категориальных фичей\n",
    "- Научим Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#вытаскиватель категориальных фичей\n",
    "vectorizer = DictVectorizer(sparse=False,dtype=np.bool)\n",
    "\n",
    "def preprocess_data(X_raw):\n",
    "    data_dict = [ {'f_class':f,'s_class':s,'t_class':t}\n",
    "               for f,s,t in X_raw[['f_class','s_class','t_class']].values ]\n",
    "\n",
    "    Xcat = vectorizer.fit_transform(data_dict)\n",
    "    \n",
    "    real_features = [\"dist\",\"lat\",\"lon\"]\n",
    "    Xreal = X_raw[real_features].values\n",
    "    Xfull = np.concatenate([\n",
    "            Xreal,\n",
    "            Xcat            \n",
    "        ],axis=1)\n",
    "    \n",
    "    return pd.DataFrame(Xfull,columns=real_features+vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = preprocess_data(X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поделим на обучение и валидацию\n",
    "* Важно, что мы делим не случайно, а по времени:\n",
    " * Валидационная выборка вся находится строго раньше тестовой\n",
    " * Это вызвано тем, что тестовые данные по времени дальше обучающих"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#обучение и тест\n",
    "pivot = int(len(X) * 0.75)\n",
    "Xtr = X[:pivot]\n",
    "Xval = X[pivot:]\n",
    "Ytr = y[:pivot]\n",
    "Yval = y[pivot:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=250,n_jobs=-1)\n",
    "model.fit(Xtr,Ytr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценим качество\n",
    "\n",
    "Посчитаем AUC и Accuracy@10k на обучении и тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for source_i, Xi,Yi in [\n",
    "                            [\"train\",Xtr,Ytr],\n",
    "                            [\"val\",Xval,Yval]\n",
    "                                ]:\n",
    "    \n",
    "    # Предскажем вероятность сгорания\n",
    "    Yi_pred_proba = model.predict_proba(Xi)[:,1]\n",
    "    \n",
    "    #Поделим предсказание на сгоревшие и не сгоревшие\n",
    "    Yi_pred_class = np.argsort(Yi_pred_proba) < 10000\n",
    "    \n",
    "    auc = roc_auc_score(Yi,Yi_pred_proba)\n",
    "    acc = accuracy_score(Yi,Yi_pred_class)\n",
    "    \n",
    "    print '%s: \\t AUC = %.5f \\t Accuracy = %.5f'%(source_i, auc, acc)\n",
    "    \n",
    "    fpr,tpr,_ = roc_curve(Yi,Yi_pred_proba)\n",
    "    \n",
    "    plt.plot(fpr,tpr,label = source_i)\n",
    "    \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отгрузим решение в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_submission(preproc_fun,model,filename=\"submission.csv\"):\n",
    "    \n",
    "    data_eval = pd.DataFrame.from_csv(\"./evaluation.handout.csv\")\n",
    "    \n",
    "    \n",
    "    x_col = [ 'dist','due', 'lat','lon','f_class','s_class','t_class',]\n",
    "    X_eval = preproc_fun(data_eval[x_col])\n",
    "    \n",
    "    # Предскажем вероятность сгорания\n",
    "    Y_pred_proba_eval = model.predict_proba(X_eval)[:,1]\n",
    "    \n",
    "    #Поделим предсказание на сгоревшие и не сгоревшие по порогу (thr)\n",
    "    \n",
    "    \n",
    "    response = pd.DataFrame()\n",
    "    response[\"Ids\"] = np.arange(len(Y_pred_proba_eval))\n",
    "    \n",
    "    response[\"Y_prob\"] = map(\"{0:.5f}\".format,Y_pred_proba_eval)\n",
    "    \n",
    "    \n",
    "    response.to_csv(filename,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_submission(preprocess_data,model,\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Советы по улучшению модели:\n",
    "\n",
    "* Смотри глазами на данные - строй графики, исследуй аномалия \n",
    " * это может принести новые идеи и отбросить нежизнеспособные намного раньше \n",
    " * Туториал по библиотеке, в которой можно строить графики \n",
    "   * http://matplotlib.org/users/pyplot_tutorial.html\n",
    " * Ключевой вопрос самому себе - __\"От чего ещё может зависеть, сгорит ли заказ?\"__\n",
    "\n",
    "\n",
    "* Попробуй более точно настроить модель или выбрать другую\n",
    " * Random Forest с текущими параметрами можно улучшить\n",
    "   * Документация по нему - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    " * А можно использовать другие, более подходящие методы\n",
    "   * Документация по методам - http://scikit-learn.org/stable/supervised_learning.html\n",
    " * Наконец, модели можно комбинировать\n",
    "   * Например, усреднять с весами\n",
    "   * В итоге качество может быть лучше, чем у каждой модели по отдельности\n",
    " * Важно не увлечься - зачастую качественные изменения решения намного лучше подкручивания параметров\n",
    "\n",
    "\n",
    "* Подумай, какие ещё дополнительные данные можно провязать с выборкой? \n",
    " * насколько реально применить их за отведённое время?\n",
    "\n",
    "\n",
    "* __Главное__ - пытайся понять, дадут ли твои улучшения прирост на новых данных\n",
    " * Тестовая выборка находится по времени дальше, чем обучающая.\n",
    "   * Например, нельзя использовать номер дня в году, потому что мы обучаемся на выборке __ДО__ начала контрольной\n",
    " * Это не значит, что нужно отправлять миллион решений на проверку и выбирать лучшее - это приведёт к переобучению\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
